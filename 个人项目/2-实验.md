# 实验项目：基于MySQL全文索引构建简单的中文“搜索引擎”
### 基础实验：实验全文索引
#### 全文索引的创建：
##### 1)在创建表时创建全文索引
create table fulltext_test (  
    id int(11) NOT NULL AUTO_INCREMENT,  
    content text NOT NULL,  
    tag varchar(255),  
    PRIMARY KEY (id),  
    FULLTEXT KEY content_tag_fulltext(content,tag)  // 创建联合全文索引列  
) ENGINE=MyISAM DEFAULT CHARSET=utf8;  

#### 测试全文索引
##### 创建测试表，插入测试数据
create table test (  
    
id int(11) unsigned not null auto_increment,  
      
content text not null,  
    
primary key(id),  
    
fulltext key content_index(content)  
//该句为创建全文索引  
) engine=MyISAM default charset=utf8;  

insert into test (content) values ('a'),('b'),('c');    
insert into test (content) values ('aa'),('bb'),('cc');    
  
insert into test (content) values ('aaa'),('bbb'),('ccc');  
insert into test (content) values ('aaaa'),('bbbb'),('cccc');  
  
##### 按照全文索引的使用语法执行下面查询：  
select * from test where match(content) against('a');  
select * from test where match(content) against('aa');  
select * from test where match(content) against('aaa');  
select * from test where match(content) against('aaaa');
 

## 基于全文索引，构建简单的“搜索引擎”(本实验测试的是使用INNODB引擎来进行全文索引)  
### 准备工作：  
##### 1.实验目标：  
- 查询文章中是否含有某个关键词；一系列文章出现某个关键词的次数  
- 查询文章的标题是否含有某个关键词  
##### 2.设置参数从而减少磁盘IO压力：  
SET GLOBAL sync_binlog=100;  
SET GLOBAL innodb_flush_log_at_trx_commit=2;  
##### 3.导入1kw条数据(1.57G)对全文索引进行测试  
数据来源：https://pan.baidu.com/s/1aaB1R3bkBGZRMEx0o6T61w  

##### 4.创建该测试所依据的文章表，其SQL语句如下：  
CREATE TABLE `article` (  
  `id` bigint(10) NOT NULL,  
  `url` varchar(1024) CHARACTER SET latin1 NOT NULL DEFAULT '',  
  `title` varchar(256) NOT NULL DEFAULT '',  
  `source` varchar(32) DEFAULT '' COMMENT '真实来源',  
  `keywords` varchar(32) DEFAULT NULL,  
  `publish_time` timestamp NULL DEFAULT NULL,  
  PRIMARY KEY (`id`),  
  KEY `title_idx` (`title`)  
) ENGINE=InnoDB  
##### 5.查看最终的数据库名称、表的名称、导入后的总数据量、导入后的数据文件和索引文件的大小、总的行数
###### SQL语句如下：
SELECT  
    a.table_schema ,  
    a.table_name ,  
    concat(round(sum(DATA_LENGTH / 1024 / 1024) + sum(INDEX_LENGTH / 1024 / 1024) ,2) ,'MB') total_size ,  
    concat(round(sum(DATA_LENGTH / 1024 / 1024) , 2) ,'MB') AS data_size ,  
    concat(round(sum(INDEX_LENGTH / 1024 / 1024) , 2) ,'MB') AS index_size,  
    AVG_ROW_LENGTH,  
    table_rows,  
    update_time  
FROM  
    information_schema. TABLES a  
WHERE  
    a.table_schema = 'fulltext_test'  
AND a.table_name = 'article';  
（初次导入了将近1000条数据后得到的结果如下：）
！[image](https://github.com/wuruiwen2000/-/blob/master/%E4%B8%AA%E4%BA%BA%E9%A1%B9%E7%9B%AE/%E4%B8%AA%E4%BA%BA-7.PNG)

### 创建全文索引的方式有以下两种，一是使用默认方式创建全文索引，二是使用ngram分词解析器创建全文索引，二者的区别是前者通过字符分词，后者根据数量来进行分词。
### 一.使用默认方式创建全文索引
##### 1.查看该表已有的关键词字段
select keywords from article limit 10;
##### 2.对不建立全文索引时和建立全文索引时查询关键词字段出现的次数进行对比进行对比：
select count(*) from article where keywords like '%时尚%';
##### 3.对关键词字段创建全文索引（以','作为分词）
###### 3.1设置自定义stopwords（分词）
设置自定义stopwords（分词）
use fulltext_test;
create table my_stopwords(value varchar(30)) engine=INNODB DEFAULT CHARSET=utf8;
insert into my_stopwords(value) value(',');
set global innodb_ft_server_stopword_table='fulltext_test/my_stopwords';

查看可查询字词的最小长度和建好的分词表
show global variables where variable_name in('innodb_ft_min_token_size','innodb_ft_server_stopword_table');
##### 3.2对于关键词字段创建全文索引
alter table article add fulltext index idx_full_keyword(keywords);
##### 3.3查看磁盘空间（保证有充足的空间存储数据）
##### 3.4利用创建的全文索引查询某个关键词出现的次数
select count(*) from article where match(keywords) against('%时尚%');
##### 3.5 如需同时匹配多个关键词（也就是包含多个关键词），用布尔全文搜索
e.g.:


表示完全匹配 "三里屯,北京" 的记录数


select count(*) from article where match(keywords)  against('+三里屯,北京' in boolean mode);

表示匹配“三里屯” 或者 “北京”的记录数


select count(*) from article where match(keywords)  against('三里屯,北京');

### 二.是使用ngram分词解析器创建全文索引（此次实现的是查询文章的标题是否含有某个关键词）
#### 1、查找article表中所有的title字段（该字段没有固定的stopwords 分词，使用ngram分词解析器）
select title from article limit 10;
#### 2.对title字段创建全文索引
alter table article add fulltext index ft_index_title(title) with parser ngram;
#### 3.查找Mysql/data中的文件，发现创建了许多倒排索引文件（title字段越长长，创建的倒排索引越大）
#### 4、不建立全文索引搜索title的某个关键词
select count(*) from article where title like '%户外%';
#### 5.使用全文索引搜索某个关键词
select count(*) from article where match(title)  against('户外')
同样可以发现响应时间大幅度提升
#### 6.在搜索的关键词字符数大于2的情况下（即ngram_token_size定义大小大于2）会出现不一致问题：
在未创建全文搜索时，实际出现关键词的记录数与通过全文搜索得到的关键词的记录数不同
select count(*) from article where title like '%公子大%';
select count(*) from article where match(title)  against('公子大');


### 实验结论：
- 对于全文索引来说，字段程度越大，建立的全文索引的长度也就越大
- 当MySQL中的某字段没有使用自行规定好的分词方式，而是使用内置解析器时，当搜索的关键词的字符数量不等于ngram_token_size定义大小时，会出现与实际情况不一致的问题。
- 当MySQL中的某字段使用自行规定好的分词方式，对该字段进行全文索引，能够在该字段内快速出现某个关键词的相关记录信息，实现简单搜索引擎的效果。
- 总结：全文索引可以起到快速搜索的效果，满足搜索引擎在短时间内获得搜索结果的要求。

### 实验心得：
#### 关于实验过程：
- 在导入数据的步骤中，我使用了两种方法（下载后的文件为多个压缩包的压缩包，体积非常大）
##### 1)该方法为最基础的简单方法，但需要时间过长，不适合导入能够完成搜索引擎要求所需的大容量数据
###### 建立好table后（注意一定要建立好），在可视化工具中直接点击“载入SQL文件”，之后选取单个已经解压了的SQL文件等待导入（1000条数据大约是1h?，总之是很慢)
##### 2）该方法使用myloader 通过多线程方法导入数据
###### 打开cmd,输入如下语句，先把测试数据进行解压：
###### tar -zxf mydumper_dump_article.tar.gz
###### time myloader -u $user -p $passwd -S $socket -t 32 -d /datas/dump_article -v 3
###### 补充：使用多线程方法需要安装mydumper
###### mydumper的一些安装条款如下：
-- mydumper安装依赖软件包：glibc, zlib, pcre, pcre-devel, gcc, gcc-c++, cmake, make, mysql客户端库文件
-- 赖软件包
yum -y install glib2-devel zlib-devel pcre-devel mysql-devel
安装mysql客户端，将客户端库文件路径添加至/etc/ld.so.conf, 如/usr/local/mysql/lib
解压软件包进入目录，cmake .
make && make install
安装后 mydumper和myloader位于/usr/local/bin目录下。
#### 关于实验结果：
- 使用like+%查询和使用建立全文索引进行查询的首要不同之处在于后者的速度更快，对于简单的搜索引擎来说，其背后一定是巨大的数据，因此想要实现搜索引擎的及时搜索，建立全文索引时必不可少的。

